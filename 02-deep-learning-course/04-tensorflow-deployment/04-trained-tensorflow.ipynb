{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the best features of TensorFlow is that we can take a model we've built, like this one, and export it to a file and then run that file on Google's cloud servers. That let's us scale up any machine learning feature we've built to an almost infinite scale without having to maintain our own servers. But in order to do that we have to tell Google how we want to run our model in production. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's several ways we can use this model. \n",
    "\n",
    "1. First, if we want to initialize all the variables to their default values, we call this init operator. \n",
    "2. If we want to generate an output we can pass an input data and then call the output operation. \n",
    "3. If we want to train the network we can call the train operator. If we export this model to a file using the normal way of saving model checkpoint files, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new saved model builder object\n",
    "\n",
    "    tf.saved_model.builder.SavedModelBuilder(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Section for Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder = tf.saved_model.builder.SaveModelBuilder('exported_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First, we have a Python dictionary with a key called inputs. In this dictionary, we'll list each tensor that needs to be filled in when their model is run. Our model takes in one tensor with nine values as input, so that means our model will have one input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs\n",
    "\n",
    "Our model takes in one tensor with nine values as input that means our mode will have one input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input\n",
    "inputs = {\n",
    "    'input': tf.saved_model.utils.build_tensor_info(X) # wrap the tensor\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs\n",
    "\n",
    "Our output is a single tensor with one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output\n",
    "outputs = {\n",
    "    'earnings': tf.saved_model.utils.build_tensor_info(prediction) # pass prediction tensor as the tensor to output\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Signature Def\n",
    "\n",
    "A signature def is sort of like a function or method declaration in the programming language. We're telling TensorFlow that to run the model it should call a certain function with certain parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create signature\n",
    "signature_def = tf.saved_model.signature_def_utils.build_signature_def(\n",
    "    inputs = inputs,\n",
    "    outputs = outputs,\n",
    "    method_name = tf.saved_model.signature_constants.PREDICT_METHOD_NAME # predefined function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the model builder on how the model is exported\n",
    "\n",
    "Use meta graph as the structure of the computational graph and the variables are the values we set on each nodein the graph. This is telling TensorFlow that we want to export everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model builder\n",
    "model_builder.add_meta_graph_and_variables(\n",
    "    session,\n",
    "    tags=[tf.saved_model.tag_constants.SERVING], # tag name which is what Google looks for when figuring out what to execute.\n",
    "    signature_def_map={\n",
    "        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\David Ly\\Anaconda3\\envs\\tf-test\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Epoch: 0 - Training Cost: 0.06766578555107117  Testing Cost: 0.07390794157981873\n",
      "Epoch: 5 - Training Cost: 0.022944960743188858  Testing Cost: 0.023265168070793152\n",
      "Epoch: 10 - Training Cost: 0.015663104131817818  Testing Cost: 0.016371354460716248\n",
      "Epoch: 15 - Training Cost: 0.008577358908951283  Testing Cost: 0.009876777417957783\n",
      "Epoch: 20 - Training Cost: 0.008599082939326763  Testing Cost: 0.009812687523663044\n",
      "Epoch: 25 - Training Cost: 0.004091870971024036  Testing Cost: 0.004667735192924738\n",
      "Epoch: 30 - Training Cost: 0.003938313107937574  Testing Cost: 0.004121948499232531\n",
      "Epoch: 35 - Training Cost: 0.0020920373499393463  Testing Cost: 0.002170512918382883\n",
      "Epoch: 40 - Training Cost: 0.0018894298700615764  Testing Cost: 0.0018961633322760463\n",
      "Epoch: 45 - Training Cost: 0.00143890839535743  Testing Cost: 0.0013506177347153425\n",
      "Epoch: 50 - Training Cost: 0.0009913675021380186  Testing Cost: 0.0009757757652550936\n",
      "Epoch: 55 - Training Cost: 0.0008650025702081621  Testing Cost: 0.0008981212158687413\n",
      "Epoch: 60 - Training Cost: 0.0007279539131559432  Testing Cost: 0.0007720967987552285\n",
      "Epoch: 65 - Training Cost: 0.0005716557498089969  Testing Cost: 0.0006374181830324233\n",
      "Epoch: 70 - Training Cost: 0.0004578748485073447  Testing Cost: 0.000531137571670115\n",
      "Epoch: 75 - Training Cost: 0.0003853591624647379  Testing Cost: 0.00046471506357192993\n",
      "Epoch: 80 - Training Cost: 0.00033027728204615414  Testing Cost: 0.0004125269188079983\n",
      "Epoch: 85 - Training Cost: 0.00028318242402747273  Testing Cost: 0.0003763737913686782\n",
      "Epoch: 90 - Training Cost: 0.0002454172645229846  Testing Cost: 0.0003364063741173595\n",
      "Epoch: 95 - Training Cost: 0.0002158132556360215  Testing Cost: 0.0003125304647255689\n",
      "Final Training cost: 0.00019609119044616818\n",
      "Final Testing cost: 0.00028782509616576135\n",
      "The actual earnings of Game #1 were $247537.0\n",
      "Our neural network predicted earnings of $251058.875\n",
      "WARNING:tensorflow:From <ipython-input-1-9d5e766cc89e>:152: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: exported_model\\saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Turn off TensorFlow warning messages in program output\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Load training data set from CSV file\n",
    "training_data_df = pd.read_csv(\"Data/sales_data_training.csv\", dtype=float)\n",
    "\n",
    "# Pull out columns for X (data to train with) and Y (value to predict)\n",
    "X_training = training_data_df.drop('total_earnings', axis=1).values\n",
    "Y_training = training_data_df[['total_earnings']].values\n",
    "\n",
    "# Load testing data set from CSV file\n",
    "test_data_df = pd.read_csv(\"Data/sales_data_test.csv\", dtype=float)\n",
    "\n",
    "# Pull out columns for X (data to train with) and Y (value to predict)\n",
    "X_testing = test_data_df.drop('total_earnings', axis=1).values\n",
    "Y_testing = test_data_df[['total_earnings']].values\n",
    "\n",
    "# All data needs to be scaled to a small range like 0 to 1 for the neural\n",
    "# network to work well. Create scalers for the inputs and outputs.\n",
    "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "Y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale both the training inputs and outputs\n",
    "X_scaled_training = X_scaler.fit_transform(X_training)\n",
    "Y_scaled_training = Y_scaler.fit_transform(Y_training)\n",
    "\n",
    "# It's very important that the training and test data are scaled with the same scaler.\n",
    "X_scaled_testing = X_scaler.transform(X_testing)\n",
    "Y_scaled_testing = Y_scaler.transform(Y_testing)\n",
    "\n",
    "# Define model parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "display_step = 5\n",
    "\n",
    "# Define how many inputs and outputs are in our neural network\n",
    "number_of_inputs = 9\n",
    "number_of_outputs = 1\n",
    "\n",
    "# Define how many neurons we want in each layer of our neural network\n",
    "layer_1_nodes = 50\n",
    "layer_2_nodes = 100\n",
    "layer_3_nodes = 50\n",
    "\n",
    "# Section One: Define the layers of the neural network itself\n",
    "\n",
    "# Input Layer\n",
    "with tf.variable_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, shape=(None, number_of_inputs))\n",
    "\n",
    "# Layer 1\n",
    "with tf.variable_scope('layer_1'):\n",
    "    weights = tf.get_variable(\"weights1\", shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n",
    "\n",
    "# Layer 2\n",
    "with tf.variable_scope('layer_2'):\n",
    "    weights = tf.get_variable(\"weights2\", shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases2\", shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)\n",
    "\n",
    "# Layer 3\n",
    "with tf.variable_scope('layer_3'):\n",
    "    weights = tf.get_variable(\"weights3\", shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases3\", shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights) + biases)\n",
    "\n",
    "# Output Layer\n",
    "with tf.variable_scope('output'):\n",
    "    weights = tf.get_variable(\"weights4\", shape=[layer_3_nodes, number_of_outputs], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases4\", shape=[number_of_outputs], initializer=tf.zeros_initializer())\n",
    "    prediction = tf.matmul(layer_3_output, weights) + biases\n",
    "\n",
    "# Section Two: Define the cost function of the neural network that will be optimized during training\n",
    "\n",
    "with tf.variable_scope('cost'):\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "    cost = tf.reduce_mean(tf.squared_difference(prediction, Y))\n",
    "\n",
    "# Section Three: Define the optimizer function that will be run to optimize the neural network\n",
    "\n",
    "with tf.variable_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Create a summary operation to log the progress of the network\n",
    "with tf.variable_scope('logging'):\n",
    "    tf.summary.scalar('current_cost', cost)\n",
    "    summary = tf.summary.merge_all()\n",
    "\n",
    "# Initialize a session so that we can run TensorFlow operations\n",
    "with tf.Session() as session:\n",
    "\n",
    "    # Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Create log file writers to record training progress.\n",
    "    # We'll store training and testing log data separately.\n",
    "    training_writer = tf.summary.FileWriter('./logs/training', session.graph)\n",
    "    testing_writer = tf.summary.FileWriter('./logs/testing', session.graph)\n",
    "\n",
    "    # Run the optimizer over and over to train the network.\n",
    "    # One epoch is one full run through the training data set.\n",
    "    for epoch in range(training_epochs):\n",
    "\n",
    "        # Feed in the training data and do one step of neural network training\n",
    "        session.run(optimizer, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n",
    "\n",
    "        # Every few training steps, log our progress\n",
    "        if epoch % display_step == 0:\n",
    "            # Get the current accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "            training_cost, training_summary = session.run([cost, summary], feed_dict={X: X_scaled_training, Y:Y_scaled_training})\n",
    "            testing_cost, testing_summary = session.run([cost, summary], feed_dict={X: X_scaled_testing, Y:Y_scaled_testing})\n",
    "\n",
    "            # Write the current training status to the log files (Which we can view with TensorBoard)\n",
    "            training_writer.add_summary(training_summary, epoch)\n",
    "            testing_writer.add_summary(testing_summary, epoch)\n",
    "\n",
    "            # Print the current training status to the screen\n",
    "            print(\"Epoch: {} - Training Cost: {}  Testing Cost: {}\".format(epoch, training_cost, testing_cost))\n",
    "\n",
    "    # Training is now complete!\n",
    "\n",
    "    # Get the final accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "    final_training_cost = session.run(cost, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n",
    "    final_testing_cost = session.run(cost, feed_dict={X: X_scaled_testing, Y: Y_scaled_testing})\n",
    "\n",
    "    print(\"Final Training cost: {}\".format(final_training_cost))\n",
    "    print(\"Final Testing cost: {}\".format(final_testing_cost))\n",
    "\n",
    "    # Now that the neural network is trained, let's use it to make predictions for our test data.\n",
    "    # Pass in the X testing data and run the \"prediciton\" operation\n",
    "    Y_predicted_scaled = session.run(prediction, feed_dict={X: X_scaled_testing})\n",
    "\n",
    "    # Unscale the data back to it's original units (dollars)\n",
    "    Y_predicted = Y_scaler.inverse_transform(Y_predicted_scaled)\n",
    "\n",
    "    real_earnings = test_data_df['total_earnings'].values[0]\n",
    "    predicted_earnings = Y_predicted[0][0]\n",
    "\n",
    "    print(\"The actual earnings of Game #1 were ${}\".format(real_earnings))\n",
    "    print(\"Our neural network predicted earnings of ${}\".format(predicted_earnings))\n",
    "\n",
    "############################################################\n",
    "########## Build Model for Production Deployment\n",
    "############################################################\n",
    "\n",
    "    model_builder = tf.saved_model.builder.SavedModelBuilder(\"exported_model\")\n",
    "\n",
    "    inputs = {\n",
    "        'input': tf.saved_model.utils.build_tensor_info(X)\n",
    "        }\n",
    "    outputs = {\n",
    "        'earnings': tf.saved_model.utils.build_tensor_info(prediction)\n",
    "        }\n",
    "\n",
    "    signature_def = tf.saved_model.signature_def_utils.build_signature_def(\n",
    "        inputs=inputs,\n",
    "        outputs=outputs,\n",
    "        method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
    "    )\n",
    "\n",
    "    model_builder.add_meta_graph_and_variables(\n",
    "        session,\n",
    "        tags=[tf.saved_model.tag_constants.SERVING],\n",
    "        signature_def_map={\n",
    "            tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature_def\n",
    "        }\n",
    "    )\n",
    "\n",
    "    model_builder.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Cloud Platform\n",
    "\n",
    "https://console.cloud.google.com\n",
    "\n",
    "https://cloud.google.com/sdk/auth_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (TensorFlow)",
   "language": "python",
   "name": "tf-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
