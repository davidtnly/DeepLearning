{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Cloud Platform\n",
    "\n",
    "https://console.cloud.google.com\n",
    "\n",
    "https://cloud.google.com/sdk/auth_success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn how to upload a custom TensorFlow model to the Google Cloud ML service. \n",
    "\n",
    "1. Make sure you have already exported the model as a .pb file\n",
    "2. Make sure that you have a properly configured Google Cloud account, with access to the Google Cloud ML service, and that you have the gcloud command line tool already installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Model in the Cloud - 2 Step Process\n",
    "\n",
    "To use this model in the Cloud, it's a two-step process. \n",
    "\n",
    "1. We'll upload the model files to a Google Cloud storage bucket. \n",
    "\n",
    "\n",
    "2. We'll create a new Google Cloud machine learning model using the files we've uploaded. \n",
    "    - Once the model is in the Cloud, we can use it by sending it data. I've included a sample data file here called sample_input_prescaled.json. This data is a simple JSON file with the name of the model's input, and then the values you want to feed into the model. \n",
    "    \n",
    "To work with the Google Cloud service, we're going to use the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open up a Terminal window on your computer, and then navigate to the folder where your model is exported.\n",
    "\n",
    "Now we can upload the model files to a Google Cloud storage bucket. We'll do that with this command. \n",
    "\n",
    "Here, we're calling __gsutil__. Gsutil is a utility that handles lots of basic Google Service operations, like creating new storage buckets, moving files around, changing permissions, and so on. mb stands for \"Make bucket.\" Next, we have to tell Google which data center to create the bucket in. \n",
    "\n",
    "Type in terminal:\n",
    "\n",
    "    gsutil mb -l us-west1 gs://tensorflow-class-247162 # be sure to set billing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the model files into the bucket\n",
    "\n",
    "    gsutil cp - R exported_model/* gs://tensorflow-class-247106/earnings_v1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tell the Google Machine Learning Engine that we want to create a new model\n",
    "\n",
    "    gcloud ml-engine models create earnings --regions us-west1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Versions on Cloud\n",
    "\n",
    "Upload multiple versions of the same model. To actually use a model, we need to upload the first version of the model. \n",
    "\n",
    "Let's try to create a named version.\n",
    "\n",
    "    gcloud ml-engine versions create v1 --model=earnings --origin=gs://tensorflow-class-247162/earnings_v1/\n",
    "\n",
    "### Model is now live in the Cloud\n",
    "\n",
    "Great, our model is now live in the Cloud, and ready to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict\n",
    "\n",
    "    gcloud ml-engine predict --model=earnings --json-instances=sample_input_prescaled.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "import googleapiclient.discovery\n",
    "\n",
    "# Change this values to match your project\n",
    "PROJECT_ID = \"tensorflow-class-247106\"\n",
    "MODEL_NAME = \"earnings\"\n",
    "CREDENTIALS_FILE = \"credentials.json\"\n",
    "\n",
    "# These are the values we want a prediction for\n",
    "inputs_for_prediction = [\n",
    "    {\"input\": [0.4999, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5]}\n",
    "]\n",
    "\n",
    "# Connect to the Google Cloud-ML Service\n",
    "credentials = GoogleCredentials.from_stream(CREDENTIALS_FILE)\n",
    "service = googleapiclient.discovery.build('ml', 'v1', credentials=credentials)\n",
    "\n",
    "# Connect to our Prediction Model\n",
    "name = 'projects/{}/models/{}'.format(PROJECT_ID, MODEL_NAME)\n",
    "response = service.projects().predict(\n",
    "    name=name,\n",
    "    body={'instances': inputs_for_prediction}\n",
    ").execute()\n",
    "\n",
    "# Report any errors\n",
    "if 'error' in response:\n",
    "    raise RuntimeError(response['error'])\n",
    "\n",
    "# Grab the results from the response object\n",
    "results = response['predictions']\n",
    "\n",
    "# Print the results!\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum code needed to make request to the Google cloud ML service\n",
    "First, on line 15, we read the account credentials from the json file, we need this to have access to make a call to the cloud service. \n",
    "\n",
    "Then, on line 16, we create the Python object to connect to the cloud ML service. \n",
    "\n",
    "Next on line 19, we format our project name, into the format that Google expects. \n",
    "\n",
    "And then, on line 20, we make a predictionary quest, where we connect to the service and send it our input data. \n",
    "\n",
    "And then, on line 26, we check for errors and as long as everything looks good\n",
    "\n",
    "Then on line 30, we get the response. \n",
    "\n",
    "And finally on line 33, we print the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (TensorFlow)",
   "language": "python",
   "name": "tf-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
