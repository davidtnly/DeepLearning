{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"../input/\"\n",
    "train_dir = \"train/train\"\n",
    "path = os.path.join(main_dir, train_dir)\n",
    "\n",
    "##########################################\n",
    "### Loading \n",
    "##########################################\n",
    "\n",
    "# Preprocess train data\n",
    "X = []\n",
    "y = []\n",
    "convert = lambda category : int(category == 'dog')\n",
    "def create_test_data(path):\n",
    "    for p in os.listdir(path):\n",
    "        category = p.split(\".\")[0]\n",
    "        category = convert(category)\n",
    "        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n",
    "        new_img_array = cv2.resize(img_array, dsize=(80, 80))\n",
    "        X.append(new_img_array)\n",
    "        y.append(category)\n",
    "    \n",
    "create_test_data(path)\n",
    "X = np.array(X).reshape(-1, 80,80,1)\n",
    "y = np.array(y)\n",
    "\n",
    "#import pickle\n",
    "#pickle.dump( X, open( \"train_x\", \"wb\" ) )\n",
    "#pickle.dump( y, open( \"train_y\", \"wb\" ) )   \n",
    "\n",
    "#Normalize data\n",
    "X = X/255.0\n",
    "\n",
    "##########################################\n",
    "### Model\n",
    "##########################################\n",
    "\n",
    "model = load_model('model.h5')\n",
    "\n",
    "##########################################\n",
    "### Evaluation\n",
    "##########################################\n",
    "\n",
    "# Preprocess test data similar to training data\n",
    "train_dir = \"test1/test1\"\n",
    "path = os.path.join(main_dir, train_dir)\n",
    "\n",
    "X_test = []\n",
    "id_line = []\n",
    "def create_test1_data(path):\n",
    "    for p in os.listdir(path):\n",
    "        id_line.append(p.split(\".\")[0])\n",
    "        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n",
    "        new_img_array = cv2.resize(img_array, dsize=(80, 80))\n",
    "        X_test.append(new_img_array)\n",
    "create_test1_data(path)\n",
    "X_test = np.array(X_test).reshape(-1,80,80,1)\n",
    "X_test = X_test/255\n",
    "\n",
    "# Predictions\n",
    "predictions = model.predict(X_test)\n",
    "predicted_val = [int(round(p[0])) for p in predictions]\n",
    "submission_df = pd.DataFrame({'id':id_line, 'label':predicted_val})\n",
    "submission_df[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "def show_images(X_train, y_train, rows_num=6):    \n",
    "    figure, axes = plt.subplots(nrows=rows_num, ncols=6, sharex=True, sharey=True, figsize=(20, rows_num * 2))\n",
    "    \n",
    "    for row_index in range(rows_num):\n",
    "        ax_row = axes[row_index]\n",
    "        images = X_train[(row_index*8):(row_index+1)*8]\n",
    "        labels = y_train[(row_index*8):(row_index+1)*8]\n",
    "        \n",
    "        for ax, img, label in zip(ax_row, images, labels):\n",
    "            ax.imshow(img)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            ax.set_title(\"Label - {}\".format(label))\n",
    "\n",
    "# Plotting model\n",
    "f, ax = plt.subplots()\n",
    "f.set_size_inches(10, 6)\n",
    "    \n",
    "ax.plot(history.history[\"loss\"], c=\"r\")\n",
    "ax.plot(history.history[\"val_loss\"], c=\"b\")\n",
    "ax.set_title(\"Error (Categorical Cross-Entropy)\")\n",
    "ax.set_ylabel(\"Value\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.legend([\"Training\", \"Validation\"], loc=\"best\");\n",
    "\n",
    "# Evaluation\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "test_score, test_accuracy = test_score\n",
    "print(\"Test data results:\")\n",
    "print(\" - error: {}\".format(test_score))\n",
    "print(\" - acc: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3 - Getting filepath and loop pic in axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory\n",
    "PATH = 'C:\\\\Users\\\\' + os.getlogin() + '\\\\Documents\\\\Programming\\\\DeepLearning\\\\09-dog-cat-classifier\\\\images'\n",
    "os.chdir(PATH)\n",
    "\n",
    "# Use Path\n",
    "MAIN_PATH = Path(PATH)\n",
    "\n",
    "# Dataframe\n",
    "targets = list()\n",
    "full_paths = list()\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['image_path'] = full_paths\n",
    "data['target'] = targets\n",
    "\n",
    "# Loop through file names\n",
    "for i in FILE_NAMES:\n",
    "    target = i.split('.')[0]\n",
    "    full_path = os.path.join(MAIN_PATH / 'original_train', i)\n",
    "    full_paths.append(full_path) # dog file location\n",
    "    targets.append(target) # dog\n",
    "    \n",
    "def get_side(img, side_type, side_size=5):\n",
    "    height, width, channel = img.shape\n",
    "    if side_type=='horizontal':\n",
    "        return np.ones((height, side_size, channel), dtype=np.float32)*255\n",
    "    return np.ones((side_size, width, channel), dtype=np.float32)*255\n",
    "\n",
    "def show_gallery(show='both'):\n",
    "    n=100\n",
    "    counter=0\n",
    "    images=list()\n",
    "    vertical_images=[]\n",
    "    rng_state=np.random.get_state()\n",
    "    np.random.shuffle(full_paths)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(targets)\n",
    "    \n",
    "    # Loop through images and target\n",
    "    for path, target in zip(full_paths, targets): # combines both file & target together\n",
    "        if target != show and show != 'both':\n",
    "            continue\n",
    "        counter=counter+1\n",
    "        if counter%100==0:\n",
    "            break\n",
    "        \n",
    "        # Load image\n",
    "        img = load_img(path, target_size=(WIDTH, HEIGHT))\n",
    "        \n",
    "        # Convert img into array\n",
    "        img = img_to_array(img)\n",
    "        hside = get_side(img, side_type='horizontal')\n",
    "        images.append(img)\n",
    "        images.append(hside) \n",
    "        \n",
    "        if counter % 10 == 0:\n",
    "            himage = np.hstack((images))\n",
    "            vside = get_side(himage, side_type='vertial')\n",
    "            vertical_images.append(himage)\n",
    "            vertical_images.append(vside)\n",
    "            \n",
    "            # Create images list\n",
    "            images=list()\n",
    "            \n",
    "    gallery = np.vstack((vertical_images))\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    title = {\n",
    "        'both': 'Dogs and Cats',\n",
    "        'cat': 'Cats',\n",
    "        'dog': 'dogs'\n",
    "    }\n",
    "    plt.title('100 Samples of {} of the dataset'.format(title[show]))\n",
    "    plt.imshow(gallery.astype(np.uint8))  \n",
    "\n",
    "show_gallery(show='cat')\n",
    "show_gallery(show='dog')\n",
    "show_gallery()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (TensorFlow)",
   "language": "python",
   "name": "tf-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
