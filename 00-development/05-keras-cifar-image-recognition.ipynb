{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "The images in the CIFAR-10 dataset are only 32 pixels by 32 pixels with 2 color channels. \n",
    "\n",
    "These are very low resolution images. We're using them here because the lower resolution will make it possible to train the neural network to recognize them relative quickly. With the same code we'll write, we'll also work for larger image sizes. To make it easy for you to look through the CIFAR-10 dataset I've included some code that will display the images from the dataset on the screen. \n",
    "\n",
    "### CIFAR-10 Specifications\n",
    "- Images are 32x32 pixels with 2 color channels\n",
    "- 10 different types, or classes of objects\n",
    "- 60,000 total images\n",
    "- 5,000 training images and 1,000 test images per class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Develop the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create a dictionary to store a list of names for each CIFAR10 class\n",
    "cifar10_class_names = {\n",
    "    0: 'Plane',\n",
    "    1: 'Car',\n",
    "    2: 'Bird',\n",
    "    3: 'Cat',\n",
    "    4: 'Deer',\n",
    "    5: 'Dog',\n",
    "    6: 'Frog',\n",
    "    7: 'Horse',\n",
    "    8: 'Boat',\n",
    "    9: 'Truck'\n",
    "}\n",
    "\n",
    "####################################################################################\n",
    "###### Load & clean the data to a usable format\n",
    "####################################################################################\n",
    "\n",
    "# Load the dataset (be sure to list variables correctly by checking the package info)\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() # helper function\n",
    "\n",
    "'''\n",
    " 1. Normalizing the data for the neural network\n",
    " \n",
    " Neural networks work best when the input data are floating point values in between \n",
    " zero and one. Normally images are stored as integer values for each pixel is a number \n",
    " between 0 and 255. So to use this data, we need to convert it from integer the floating \n",
    " point and then we need to make sure all the values are between zero and one. \n",
    " Let's convert the data to floating point values. We can do that by using the as type function \n",
    " and passing in float 32. \n",
    "'''\n",
    "\n",
    "# Normalize the data range to 0 - 1 (change data type to float32 so there are no division errors)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255 # divide array by a single value\n",
    "x_test = x_test / 255\n",
    "\n",
    "'''\n",
    " 2. Create categorical labels for our output data\n",
    " \n",
    " Cifar10 provides the labels for each class as values from zero to nine. But since we are \n",
    " creating a neural network with 10 outputs, we need a separate expected value for each of \n",
    " those outputs. So we need to convert each label from a single number into an array with 10 elements. \n",
    " In that array, one element should be set to one and the rest set to zero. This is something you'll \n",
    " almost always need to do with your training data so keras provides a helper function.\n",
    "'''\n",
    "\n",
    "# Our labels are single values from 0 to 9 because CIFAR provides 10 classes\n",
    "# Instead, we want each label to be an array with on element set to 1 and and the rest set to 0\n",
    "y_train = keras.utils.to_categorically(y_train, 10) # pass in your array with the labels\n",
    "y_test = keras.utils.to_categorically(y_test, 10)\n",
    "\n",
    "####################################################################################\n",
    "###### Creating the neural network\n",
    "####################################################################################\n",
    "\n",
    "''' \n",
    " The simplest type of neural network has an input, \n",
    " a densely connected layer and then an output. Let's start by creating that. \n",
    "\n",
    " 1. First, create a sequential model, sequential api lets us create a neural network by \n",
    "    adding new layers to it one at a time.  It's call sequential because you add each layer \n",
    "    in sequence and they automatically get connected together in that order.\n",
    "'''\n",
    "\n",
    "# Create a model and add layers\n",
    "model = keras.models.Sequential() # create a new neural network object \n",
    "\n",
    "\n",
    "'''\n",
    "  Add convolutional layers (32);\n",
    "  \n",
    "  1. Convolutional layers are able to look for patterns in an image, no matter where the pattern appears\n",
    "  in the image. Add in a 2D layer for images (1D for sound waves)\n",
    "\n",
    "  2. The first parameter is how many different filters should be in the layer. Each filter will be capable \n",
    "  of detecting one pattern in the image. We'll start with 32. \n",
    "  \n",
    "  3. Next, we need to pass in the size of the window that we'll use when creating image tiles from each image. \n",
    "  Let's use a window size of 3x3 pixels.  This will split up the original image into 3x3 tiles.\n",
    "  \n",
    "  Add padding for edges;\n",
    "  \n",
    "   4. When we do that, we have to decide what to do with the edges of the image. If the image size isn't exactly \n",
    "   divisible by three, we'll have a few extra pixels left over on the edge. We can either throw that information \n",
    "   away, or we can add padding to the image. \n",
    "   \n",
    "       Padding is just extra zeros added to the edge of the image to make the math work out. The terminology that \n",
    "       Keras uses here is a bit confusing. If we want to add extra padding to the image, it's called same padding. \n",
    "       \n",
    "       There's complex historical reasons why researchers used the term same, but it's easier just to memorize it. \n",
    "       For this layer, we do want to have padding, so we'll pass in a parameter padding equals, and the string same, \n",
    "       and just like the normal dense layer, convolutional layers also need an activation function. \n",
    "'''\n",
    "\n",
    "# Add the first convolutional layer\n",
    "# params = (filters, window size, padding, activation, input shape)\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3))) # RGB\n",
    "\n",
    "# Add a second convolutional layer without padding since the image will not pass through this layer\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "'''\n",
    "  Add Max Pooling Layers 1;\n",
    "  \n",
    "   Max pooling is where we scale down the output of the convolutional layers by keeping only the largest values \n",
    "   and throwing away the smaller ones. This makes the neural network more efficient by throwing away the least \n",
    "   useful data and keeping the most useful data. Typically, we'll do max pooling right after a block of \n",
    "   convolutional layers. \n",
    "   \n",
    "   1. Create a new max pooling 2D layer with the pool_size parameter with (2, 2). This parameter means that we'll \n",
    "   divide the image up into 2x2 squares and only take the large values from each 2x2 region. This will reduce the\n",
    "   size of our image while keeping the most important values.\n",
    "'''\n",
    "\n",
    "# Add max pooling layer\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=2, 2)) # 2x2 box\n",
    "\n",
    "'''\n",
    "  Add Dropout Layer (1);\n",
    "  \n",
    "   One of the problems with neural networks is that they can tend to memorize the input data instead of \n",
    "   actually learning how to tell different objects apart. We can force the neural network to try harder to \n",
    "   learn without memorizing the input data. \n",
    "   \n",
    "   The idea is that between certain layers, we'll randomly throw away some of the data by cutting \n",
    "   some of the connections between the layers. This is called dropout. Usually we'll \n",
    "   add dropout right after max pulling layers, or after a group of dense layers. \n",
    "  \n",
    "  1. Create a dropout layer with 25% dropout  \n",
    "'''\n",
    "\n",
    "# Add dropout layer\n",
    "model.add(keras.layers.Dropout(0.25)) # dropout 25% of the nodes\n",
    "\n",
    "'''\n",
    "  Add convolutional layers (64);\n",
    "  \n",
    "  1. Create a second convolutionary layer with 64 filters the same way\n",
    "'''\n",
    "\n",
    "# Add in the third layer with 64 filters with padding\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "\n",
    "# Add in the fourth layer with 64 filters without padding\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "'''\n",
    "   Add Max Pooling Layers 2;\n",
    "   \n",
    "   Instead of increasing the size of our neural network, they're actually helping us decrease the \n",
    "   size by scaling down the data that passes through them while keeping the most important values. \n",
    "   This will help us speed up the training process. \n",
    "   \n",
    "   1. Create a second max pooling layer after the next two convolutionary layers the same way\n",
    "'''\n",
    "\n",
    "# Add in second max pooling layer\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "'''\n",
    "  Add Dropout Layer (2);\n",
    "  \n",
    "  1. Create a second dropout layer with 25% dropout\n",
    "'''\n",
    "\n",
    "# Add in second dropout layer\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "'''\n",
    "  Flatten Layer - transitioning to a dense layer (data needs to be flat vs. 3 layers)\n",
    "  \n",
    "   Whenever we transition between convolutional layers and dense layers, we need to tell Keras that we're \n",
    "   no longer working with 2D data. To do that we need to create a flattened layer and add it to our network. \n",
    "   We can do that by calling model.add, and creating a new flattened layer, and there's no parameters required \n",
    "   for a flattened layer.\n",
    "'''  \n",
    "\n",
    "# Add a flatten layer\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "'''\n",
    "  Add a new layer and pass in a Dense layer object;\n",
    "  \n",
    "  1.  First, we need to tell it how many nodes to include in the layer. Let's add 512 nodes \n",
    "  to this layer. So we'll just pass in 512. Next we need to tell it what activation function \n",
    "  we want to use for this layer. \n",
    "  \n",
    "  Add Activation Function;  \n",
    "  \n",
    "  2. For a normal layer like this, a common choice is to use a rectified \n",
    "  linear unit or relu activation function. It's the standard choice when working with images because \n",
    "  it works well and is computationally efficient.\n",
    "  \n",
    "  Input shape for the first layer\n",
    "  \n",
    "  3.  All the images in our data set are 32 pixels by 32 pixels and have a red green and blue channel. \n",
    "  So for the input size we'll use 32 by 32 by 3.\n",
    "  \n",
    "'''\n",
    "\n",
    "# Add a dense layer\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "\n",
    "'''\n",
    "  Add Dropout Layer (3);\n",
    "  \n",
    "  1. Create a third dropout layer with 50% dropout\n",
    "'''\n",
    "\n",
    "model.add(keras.layers.Dropout(0.50))\n",
    "\n",
    "'''\n",
    "   Add an output layer;\n",
    "   \n",
    "   We'll need one node in the output layer for each kind of object we want to detect. The cifar10 data set has \n",
    "   10 different kinds of objects. Since we're detecting 10 different kinds of objects, we'll create a new dense \n",
    "   layer with 10 nodes. \n",
    "   \n",
    "   1. So to do that we'll call model.add and we'll create a new dense object and we know it \n",
    "   needs 10 nodes. \n",
    "   \n",
    "   Softmax Classification;\n",
    "   \n",
    "   When doing classification with more than one type of object, the output layer will almost \n",
    "   always use a softmax activation function. \n",
    "   \n",
    "   What is softmax?\n",
    "   \n",
    "   The softmax activation function is a special function that makes sure all the output values from this \n",
    "   layer add up to exactly one. The idea is that each output is a value that represents the percent \n",
    "   likelihood that a certain type of object was detected. And all 10 values should add up to 100 % or 1. \n",
    "'''\n",
    "\n",
    "# Add an output layer\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "'''\n",
    "  Compile the model;\n",
    "  \n",
    "  When we compile it, we're telling Keras we actually want to create the neural network in memory. \n",
    "  We're also telling Keras how we'll be training it and measuring its accuracy. \n",
    "\n",
    "  1. Compile the model with parameters: loss, optimizer, metrics\n",
    "  \n",
    "      Loss\n",
    "          Tell Keras how to check how right or wrong the guesses from our neural network are. \n",
    "          This is called the loss function.\n",
    "          \n",
    "      Optimizer\n",
    "          Optimization algorithm we'll use to train the neural network called Adam.\n",
    "          Adam stands for Adaptive Moment Estimation. \n",
    "          \n",
    "      Metrics\n",
    "           What metrics we want it to report during the training process. Pass in an array for multiple.\n",
    "'''\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', # binary_crossentropy if 2\n",
    "    optimizer='adam',\n",
    "    metrics='accuracy'\n",
    ")\n",
    "\n",
    "# Print a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Read Model Summary: 7 Layers\n",
    "\n",
    "Alright, we can see the neural network now has seven layers. \n",
    "\n",
    "We have four convolutional layers, the flattened layer, and then our two dense layers. Notice that each layer also has a number of parameters listed. This is the total number of weights in that layer. \n",
    "\n",
    "There's also a total number at the bottom for the whole network. As we add more layers that total number will keep increasing. This is the size or complexity of our neural network. The larger the number, the longer it'll take to train and the more data we'll need to train it. \n",
    "\n",
    "It's a good idea to keep an eye on this number as you add layers to your neural network. As you test and refine your neural network, you might find that you can get good results even after you remove some of your layers and reduce this number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  Train the model;\n",
    "  \n",
    "  \n",
    "  1. model.fit() - pass in X and y\n",
    "      \n",
    "      parameters\n",
    "      \n",
    "      batch size - is how many images we want to feed into the network at once during training. \n",
    "      If we set the number too low, training will take a long time and might not ever finish. \n",
    "      If we set the number too high, we'll run out of memory on our computer. Typical batch sizes \n",
    "      are between 32 and 128 images\n",
    "\n",
    "      epoch - decide how many times we wanna go through our training data set during the process. \n",
    "      One full pass through the entire training data set is called an epoch. For this example, \n",
    "      let's do 30 passes through the training data set. So, we'll pass in epochs equals 30. So, \n",
    "      we'll pass in epochs equals 30. The more passes through the data we do, the more chance the \n",
    "      neural network has to learn; but the longer the training process will take. And eventually \n",
    "      you'll hit a point where doing additional training doesn't help anymore\n",
    "      \n",
    "      validation data - unseen data to be tested on\n",
    "      \n",
    "      shuffle = true - make sure that keras randomizes the order of the training data. It's very important \n",
    "      that the neural network sees the training data batches in random order, so that the order of the \n",
    "      training data doesn't influence the training. \n",
    "'''\n",
    "\n",
    "# Parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 5\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCH,\n",
    "    validation_data=(x_test, y_test),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "'''\n",
    "  Save neural network structure;\n",
    "\n",
    "  Save the structure of the neural network itself. That includes which layers get created and the order\n",
    "  their hooked together.\n",
    "  \n",
    "  1. Convert the structure of a neural network into JSON by calling the model dot to JSON function. \n",
    "  \n",
    "  Now, we just need to write this JSON data to a text file.\n",
    "  \n",
    "  2.  First we'll create a new path object, so we'll say, 'f' for file equals path, and then we'll \n",
    "  pass in the name of the file we wanna create. So I'm just gonna call it model structure dot JSON. \n",
    "  \n",
    "  3.  Then we just need to call the right text function of the path object and pass in the data \n",
    "  that we wanna write to the file.  So I'll do 'f' dot write text and the data that I want to write \n",
    "  is this model structure object, so I'll pass in model structure.\n",
    "'''\n",
    "\n",
    "# Save neural network structure\n",
    "model_structure = model.to_json()\n",
    "f = Path('model_structure.json')\n",
    "f.write_text(model_structure) # model object\n",
    "\n",
    "'''\n",
    "  Save neural network trained weights;\n",
    "\n",
    "  After saving the structure, we want to save the weights of the neural network. As a neural network is\n",
    "  trained, the weights of each node are adjusted to control how the signals flow through the network.\n",
    "  \n",
    "  So by saving the weights, we are saving how the neural network actually works. The reason we save the structure\n",
    "  separately from the weights is because often you'll train the same neural network multiple times with different\n",
    "  settings or different training datasets.\n",
    "  \n",
    "  It's convenient to be able to load different sets of weights using the same neural network structure. So \n",
    "  first, let's save the neural network structure itself. \n",
    "  \n",
    "  1. Use sample_weights() and save it into a binary format called HDF5. The HDF5 format is designed for saving\n",
    "  and loading large binary files efficiently.\n",
    "'''\n",
    "\n",
    "# Save neural network's trained weights\n",
    "model.save_weights('epoch_five_model_weights.h5') # h5 file type\n",
    "\n",
    "# Print a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prediction\n",
    "1. Load the json file that contains the model's structure\n",
    "\n",
    "2. Recreate the Keras model object from the json data\n",
    "\n",
    "3. Re-load the model's trained weights\n",
    "\n",
    "4. Load an image file to test, resizing it to 32x32 pixels (as required by this model)\n",
    "\n",
    "5. Convert the image to a numpy array\n",
    "\n",
    "6. Add a fourth dimension to the image (since Keras expects a list of images, not a single image)\n",
    "\n",
    "7. Make a prediction using the model\n",
    "\n",
    "8. Since we are only testing one image, we only need to check the first result\n",
    "\n",
    "9. We will get a likelihood score for all 10 possible classes. Find out which class had the highest score.\n",
    "\n",
    "10. Get the name of the most likely class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
