{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing: Train a dog/cat image classifier (TensorFlow and Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MultiLayer Perceptrons (MLP), the vanilla Neural Networks, each layer’s neurons connect to all the neurons in the next layer. We call this type of layers fully connected.\n",
    "\n",
    "A Convolutional Neural Network is different: they have Convolutional Layers.\n",
    "\n",
    "On a fully connected layer, each neuron’s output will be a linear transformation of the previous layer, composed with a non-linear activation function (e.g., ReLu or Sigmoid).\n",
    "\n",
    "Conversely, the output of each neuron in a Convolutional Layer is only a function of a typically small subset of the previous layer’s neurons.\n",
    "\n",
    "Outputs on a Convolutional Layer will be the result of applying a convolution to a subset of the previous layer’s neurons, and then an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a convolution?\n",
    " \n",
    "The convolution operation, given an input matrix A (usually the previous layer’s values) and a (typically much smaller) weight matrix called a kernel or filter K, will output a new matrix B.\n",
    "\n",
    "If K is a CxC matrix, the first element in B will be the result of:\n",
    "\n",
    "- Taking the first CxC submatrix of A\n",
    "- Multiplying each of its elements by its corresponding weight in K\n",
    "- Adding all the products\n",
    "\n",
    "These two last steps are equivalent to flattening both A’s submatrix and K, and computing the dot product of the resulting vectors.\n",
    "\n",
    "We then slide K to the right to get the next element, and so on, repeating this process for each of A‘s rows.\n",
    "\n",
    "This makes a convolutional layer much lighter than a fully connected one, helping convolutional models learn a lot faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why does this work? - [Interactive Kernels](http://setosa.io/ev/image-kernels/)\n",
    "\n",
    "Why can we ignore how each neuron affects most of the others? Well, this whole system holds up on the premise that each neuron is strongly affected by its'neighbors'. Faraway neurons, however, have only a small bearing on it.\n",
    "\n",
    "This assumption is intuitively true in images–if we think of the input layer, each neuron will be a pixel or a pixel’s RGB value. And that’s part of the reason why this approach works so well for image classification.\n",
    "\n",
    "For example, if I take a region of a picture where there’s a blue sky, it’s likely that nearby regions will show the sky as well, using similar tones.\n",
    "\n",
    "A pixel’s neighbors will usually have similar RGB values to it. If they don’t, then that probably means we are on the edge of a figure or object.\n",
    "\n",
    "If you do some convolutions with pen and paper (or a calculator), you’ll realize certain kernels will increase an input’s intensity if it’s on a certain kind of edge. In other edges, they could decrease it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Image Data w/ Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network receives a feature vector or matrix as an input, typically with fixed dimensions.\n",
    "\n",
    "Python’s Image library provides us an easy way to load an image as a NumPy array. A HeightxWidth matrix of RGB values.\n",
    "\n",
    "We still have to fix the fixed dimensions part: which dimensions do we choose for our input layer?\n",
    "\n",
    "This is important, since we will have to resize every picture to the chosen resolution. We do not want to distort aspect ratios too much in case it brings too much noise for the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create function to get images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (94, 125)\n",
    "\n",
    "def pixels_from_path(file_path):\n",
    "    '''\n",
    "    Open up image and convert to an array\n",
    "    '''\n",
    "    img = Image.open(file_path)\n",
    "    img = img.resize(IMG_SIZE)\n",
    "    img_array = np.array(img)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('training/cats/*')[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "shape_counts = defaultdict(int)\n",
    "for i, pic in enumerate(glob.glob('cats/*')[:1000]):\n",
    "    if i%100==0:\n",
    "        print(i)\n",
    "    # Get image shape from image in the folder\n",
    "    img_shape = pixels_from_path(pic).shape\n",
    "    shape_counts[str(img_shape)] = shape_counts[str(img_shape)] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% of the data will automatically be used for validation\n",
    "validation_size = 0.1\n",
    "img_size = IMG_SIZE\n",
    "num_channels = 3\n",
    "sample_size = 8192 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image count\n",
    "len(glob.glob('training/cats/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "SAMPLE_SIZE = 2048\n",
    "print(\"loading training cat images...\")\n",
    "cat_train_set = np.asarray([pixels_from_path(cat) for cat in glob.glob('training/cats/*')[:SAMPLE_SIZE]])\n",
    "print(\"loading training dog images...\")\n",
    "dog_train_set = np.asarray([pixels_from_path(dog) for dog in glob.glob('training/dogs/*')[:SAMPLE_SIZE]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set\n",
    "valid_size = 512\n",
    "print(\"loading validation cat images...\")\n",
    "cat_valid_set = np.asarray([pixels_from_path(cat) for cat in glob.glob('cats/*')[-valid_size:]])\n",
    "print(\"loading validation dog images...\")\n",
    "dog_valid_set = np.asarray([pixels_from_path(dog) for dog in glob.glob('dogs/*')[-valid_size:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "x_train = np.concatenate([cat_train_set, dog_train_set])\n",
    "labels_train = np.asarray([1 for _ in range(SAMPLE_SIZE)]+[0 for _ in range(SAMPLE_SIZE)])\n",
    "\n",
    "# Validation\n",
    "x_valid = np.concatenate([cat_valid_set, dog_valid_set])\n",
    "labels_valid = np.asarray([1 for _ in range(valid_size)]+[0 for _ in range(valid_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_size = 128\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "# Add layers\n",
    "conv_inputs = keras.Input(shape=(img_size[1], img_size[0], 3), name='ani_image')\n",
    "\n",
    "# Add convolutional layer with pooling\n",
    "conv_layer = layers.Conv2D(24, kernel_size=3, activation='relu')(conv_inputs)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2, 2))(conv_layer)\n",
    "\n",
    "# Flatten before dense layers\n",
    "conv_x = layers.Flatten(name = 'flattened_features')(conv_layer) # turn image to vector\n",
    "\n",
    "# Add dense layers\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer')(conv_x)\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='class')(conv_x)\n",
    "\n",
    "conv_model = keras.Model(inputs=conv_inputs, outputs=conv_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customAdam = keras.optimizers.Adam(lr=1e-6)\n",
    "conv_model.compile(optimizer=customAdam,  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=\"binary_crossentropy\",\n",
    "              # List of metrics to monitor\n",
    "              metrics=[\"binary_crossentropy\",\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = conv_model.fit(x_train, \n",
    "                    labels_train, #we pass it th labels\n",
    "                    #If the model is taking forever to train, make this bigger\n",
    "                    #If it is taking forever to load for the first epoch, make this smaller\n",
    "                    batch_size=32, \n",
    "                    shuffle = True,\n",
    "                    epochs=5,\n",
    "                    # We pass it validation data to\n",
    "                    # monitor loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(x_valid, labels_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_quantity = sum(labels_valid)\n",
    "\n",
    "for i in range(1,10):\n",
    "    print('threshold :'+str(.1*i))\n",
    "    print(sum(labels_valid[preds > .1*i])/labels_valid[preds > .1*i].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds.mean())\n",
    "print(preds[labels_valid == 0].mean())\n",
    "print(preds[labels_valid == 1].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
