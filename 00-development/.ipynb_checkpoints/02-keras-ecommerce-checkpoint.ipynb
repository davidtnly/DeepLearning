{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Keras Model\n",
    "\n",
    "There are some basic steps to train and test a machine learning model for any kind of problem.\n",
    "\n",
    "1. Selection of machine learning model.\n",
    "\n",
    "\n",
    "2. Train the model.\n",
    "\n",
    "\n",
    "3. Test the model.\n",
    "\n",
    "\n",
    "4. Evaluate the model.\n",
    "\n",
    "This process is called the model train test evaluation flow. The testing data should be different than the training data as predicting correct results on unseen data shall truly determine the accuracy of the model.\n",
    "\n",
    "Keras makes it simple to model a complex neural network and still gives you a large amount of control over the structure of each layer. Decide the structure of the neural network as follow:\n",
    "\n",
    "- Number of input and output\n",
    "- Number of hidden layers\n",
    "- Number of nodes or activation units in each layer\n",
    "- Type of the layers (Fully connected, convolutional, recurrent…etc.)\n",
    "- Activation function for each layer (softmax, relu, leaky relu, sigmoid…etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Email  \\\n",
      "0      mstephenson@fernandez.com   \n",
      "1              hduke@hotmail.com   \n",
      "2               pallen@yahoo.com   \n",
      "3        riverarebecca@gmail.com   \n",
      "4  mstephens@davidson-herman.com   \n",
      "\n",
      "                                             Address            Avatar  \\\n",
      "0     835 Frank Tunnel\\r\\nWrightmouth, MI 82180-9605            Violet   \n",
      "1   4547 Archer Common\\r\\nDiazchester, CA 06566-8576         DarkGreen   \n",
      "2  24645 Valerie Unions Suite 582\\r\\nCobbborough,...            Bisque   \n",
      "3  1414 David Throughway\\r\\nPort Jason, OH 22070-...       SaddleBrown   \n",
      "4  14023 Rodriguez Passage\\r\\nPort Jacobville, PR...  MediumAquaMarine   \n",
      "\n",
      "   Avg. Session Length  Time on App  Time on Website  Length of Membership  \\\n",
      "0            34.497268    12.655651        39.577668              4.082621   \n",
      "1            31.926272    11.109461        37.268959              2.664034   \n",
      "2            33.000915    11.330278        37.110597              4.104543   \n",
      "3            34.305557    13.717514        36.721283              3.120179   \n",
      "4            33.330673    12.795189        37.536653              4.446308   \n",
      "\n",
      "   Yearly Amount Spent  \n",
      "0           587.951054  \n",
      "1           392.204933  \n",
      "2           487.547505  \n",
      "3           581.852344  \n",
      "4           599.406092  \n",
      "(500, 8)\n",
      "Shape of Y_training (350,)\n",
      "Shape of Y_testing (150,)\n",
      "(350, 1)\n",
      "(150, 1)\n",
      "(150, 4)\n",
      "(150, 1)\n",
      "Note: Y values were scaled by multiplying by 0.0020510663 and adding -0.5264\n",
      "Epoch 1/50\n",
      " - 0s - loss: 0.0529\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.0166\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.0084\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.0058\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.0048\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.0039\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.0031\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.0024\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.0020\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.0016\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.0013\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.0010\n",
      "Epoch 13/50\n",
      " - 0s - loss: 8.3882e-04\n",
      "Epoch 14/50\n",
      " - 0s - loss: 6.5134e-04\n",
      "Epoch 15/50\n",
      " - 0s - loss: 7.6829e-04\n",
      "Epoch 16/50\n",
      " - 0s - loss: 5.0455e-04\n",
      "Epoch 17/50\n",
      " - 0s - loss: 4.6004e-04\n",
      "Epoch 18/50\n",
      " - 0s - loss: 4.8217e-04\n",
      "Epoch 19/50\n",
      " - 0s - loss: 5.0386e-04\n",
      "Epoch 20/50\n",
      " - 0s - loss: 4.3578e-04\n",
      "Epoch 21/50\n",
      " - 0s - loss: 4.4259e-04\n",
      "Epoch 22/50\n",
      " - 0s - loss: 4.3692e-04\n",
      "Epoch 23/50\n",
      " - 0s - loss: 3.9926e-04\n",
      "Epoch 24/50\n",
      " - 0s - loss: 3.7106e-04\n",
      "Epoch 25/50\n",
      " - 0s - loss: 3.8273e-04\n",
      "Epoch 26/50\n",
      " - 0s - loss: 3.7111e-04\n",
      "Epoch 27/50\n",
      " - 0s - loss: 3.8653e-04\n",
      "Epoch 28/50\n",
      " - 0s - loss: 5.1152e-04\n",
      "Epoch 29/50\n",
      " - 0s - loss: 4.8608e-04\n",
      "Epoch 30/50\n",
      " - 0s - loss: 4.2007e-04\n",
      "Epoch 31/50\n",
      " - 0s - loss: 3.5844e-04\n",
      "Epoch 32/50\n",
      " - 0s - loss: 4.2590e-04\n",
      "Epoch 33/50\n",
      " - 0s - loss: 4.4145e-04\n",
      "Epoch 34/50\n",
      " - 0s - loss: 4.1660e-04\n",
      "Epoch 35/50\n",
      " - 0s - loss: 4.4752e-04\n",
      "Epoch 36/50\n",
      " - 0s - loss: 5.2707e-04\n",
      "Epoch 37/50\n",
      " - 0s - loss: 4.2099e-04\n",
      "Epoch 38/50\n",
      " - 0s - loss: 4.0248e-04\n",
      "Epoch 39/50\n",
      " - 0s - loss: 3.5808e-04\n",
      "Epoch 40/50\n",
      " - 0s - loss: 3.6389e-04\n",
      "Epoch 41/50\n",
      " - 0s - loss: 4.8483e-04\n",
      "Epoch 42/50\n",
      " - 0s - loss: 5.2793e-04\n",
      "Epoch 43/50\n",
      " - 0s - loss: 4.2990e-04\n",
      "Epoch 44/50\n",
      " - 0s - loss: 3.7386e-04\n",
      "Epoch 45/50\n",
      " - 0s - loss: 3.9777e-04\n",
      "Epoch 46/50\n",
      " - 0s - loss: 3.7608e-04\n",
      "Epoch 47/50\n",
      " - 0s - loss: 3.6091e-04\n",
      "Epoch 48/50\n",
      " - 0s - loss: 3.5388e-04\n",
      "Epoch 49/50\n",
      " - 0s - loss: 4.6429e-04\n",
      "Epoch 50/50\n",
      " - 0s - loss: 3.7298e-04\n",
      "The mean squared error (MSE) for the test data set is: 0.029196480214595796\n",
      "Earnings Prediction for Proposed Product - $360.3992919921875\n",
      "Real Value of the Product - $451.57568515949305\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "## Preprocessing\n",
    "############################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('ecommerce_customers')\n",
    "\n",
    "# Check dimensions and data\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "\n",
    "############################\n",
    "## Split and scale \n",
    "############################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Split training\n",
    "# y = data['Yearly Amount Spent']\n",
    "# X = data.drop(['Yearly Amount Spent'], axis=1)\n",
    "y = data['Yearly Amount Spent'].values\n",
    "X = data[['Avg. Session Length', 'Time on App', 'Time on Website','Length of Membership']].values\n",
    "\n",
    "# Assign variables for test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=100)\n",
    "\n",
    "print('Shape of Y_training', y_train.shape)\n",
    "print('Shape of Y_testing', y_test.shape)\n",
    "\n",
    "# Reshape the data\n",
    "y_train_re = np.reshape(y_train, (-1, 1)) # Data has to be 1D so use .values if didn't already\n",
    "y_test_re = np.reshape(y_test, (-1, 1))\n",
    "\n",
    "print(y_train_re.shape)\n",
    "print(y_test_re.shape)\n",
    "\n",
    "# Scale to a range from 0 to 1 for neural networks to work well\n",
    "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale both the training inputs and outputs\n",
    "X_scaled_train = X_scaler.fit_transform(X_train)\n",
    "y_scaled_train = y_scaler.fit_transform(y_train_re)\n",
    "\n",
    "# Scale test data\n",
    "X_scaled_test = X_scaler.fit_transform(X_test)\n",
    "y_scaled_test = y_scaler.fit_transform(y_test_re)\n",
    "\n",
    "print(X_scaled_test.shape)\n",
    "print(y_scaled_test.shape)\n",
    "print(\"Note: Y values were scaled by multiplying by {:.10f} and adding {:.4f}\".format(y_scaler.scale_[0], y_scaler.min_[0]))\n",
    "\n",
    "############################\n",
    "## Model Development\n",
    "############################\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=4, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_scaled_train,\n",
    "    y_scaled_train,\n",
    "    epochs=50,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_error_rate = model.evaluate(X_scaled_test, y_scaled_test, verbose=0)\n",
    "print(\"The mean squared error (MSE) for the test data set is: {}\".format(test_error_rate))\n",
    "\n",
    "y_predicted_scaled = model.predict(X_scaled_test)\n",
    "\n",
    "# Unscale the data back to it's original units (dollars)\n",
    "y_predicted = y_scaler.inverse_transform(y_predicted_scaled)\n",
    "\n",
    "# Grab just the first element of the first prediction \n",
    "prediction = y_predicted[0][0]\n",
    "real_earnings = y_test[0]\n",
    "\n",
    "print(\"Earnings Prediction for Proposed Product - ${}\".format(prediction))\n",
    "print(\"Real Value of the Product - ${}\".format(real_earnings))\n",
    "\n",
    "############################\n",
    "## Save, Load, Predict\n",
    "############################\n",
    "\n",
    "# model.save(\"keras_model_1.h5\")\n",
    "# model = keras.models.load_model(\"keras_model_1.h5\")\n",
    "# predictions = model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earnings Prediction for Proposed Product - $360.3992919921875\n",
      "Real Value of the Product - $451.57568515949305\n"
     ]
    }
   ],
   "source": [
    "print(\"Earnings Prediction for Proposed Product - ${}\".format(prediction))\n",
    "print(\"Real Value of the Product - ${}\".format(real_earnings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (TensorFlow)",
   "language": "python",
   "name": "tf-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
