{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning to build an image recognition system that can identify pictures of dogs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Feature Extractor\n",
    "The first step is to build a feature extractor that can extract training features from our images.\n",
    "\n",
    "1. Load libraries, images, training data\n",
    "2. Build a VGG model without the top layer (include_top=False)\n",
    "3. Predict training data\n",
    "4. Extract features and labels using joblib into a dat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import vgg16\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Training folder\n",
    "training_folder = 'TrainingData/'\n",
    "subfolder_dogs = '/dogs/'\n",
    "subfolder_not_dogs = '/not_dogs/'\n",
    "\n",
    "# Create path to folders with training data\n",
    "dog_path = Path(training_folder) / subfolder_dogs\n",
    "not_dog_path = Path(training_folder) / subfolder_not_dogs\n",
    "\n",
    "# Create an images and labels list to store arrays; assign 0 or 1 as labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Loop through not-dog images (not_dog_path)\n",
    "for img in not_dog_path.glob('*.png'): # return a possibly-empty list of path names that match pathname \"*.png\"\n",
    "    \n",
    "    # Load the image from disk\n",
    "    img = image.load_img(img)\n",
    "    \n",
    "    # Convert the image to a numpy array\n",
    "    image_array = image.img_to_array(img) # keras helper function to convert image into an array\n",
    "    \n",
    "    # Add the image to the lsit of images\n",
    "    images.append(image_array) # add image appray to list of images\n",
    "    \n",
    "    # Add labels which is 0 for not dogs\n",
    "    labels.append(0) # add 0 to label array\n",
    "    \n",
    "# Load all the dog images\n",
    "for img in dog_path.glob('*.png'):\n",
    "    \n",
    "    # Load the image from disk\n",
    "    img = image.load_img(img)\n",
    "    \n",
    "    # Convert the image to a numpy array\n",
    "    image_array = image.img_to_array(img)\n",
    "    \n",
    "    # Add the image to the list of images\n",
    "    images.append(image_array)\n",
    "    \n",
    "    # For each dog image, the expected value should be 1\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data array (x & y)\n",
    "Create an array called x_train that will have the training data. Keras expects all of our training images to be a numpy array instead of a normal Python list.\n",
    "\n",
    "1. Create a single numpy array with all the images laoded\n",
    "2. Convert the labels to a numpy array\n",
    "3. Normalize from 0 to 1\n",
    "4. Pre-trained neural network\n",
    "5. Extract features for each image (all in one pass)\n",
    "6. Save the array of extracted features to a file\n",
    "7. Save the matching array of expected values to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single numpy array with all the images\n",
    "x_train = np.array(images)\n",
    "\n",
    "# Convert labels to a numpy array as well\n",
    "y_train = np.array(labels)\n",
    "\n",
    "# Normalize\n",
    "x_train = vgg16.preprocess_input(x_train)\n",
    "\n",
    "# Load a pre-trained neural network to extract features; remove last layer of the neural network\n",
    "pretrained_nn = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3)) \n",
    "\n",
    "# Extract features for each image\n",
    "# Features x array will now contain the set of features that represent each of the training images in our dataset\n",
    "features_x = pretrained_nn.predict(x_train)\n",
    "\n",
    "# Save the array of extracted features to a file\n",
    "joblib.dump(features_x, 'x_train.dat')\n",
    "\n",
    "# Save the matching array of expected values to a file\n",
    "joblib.dump(y_train, 'y_train.dat') # These files contain the features and labels that represent our training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a New Neural Network w/ Extracted Features (Load)\n",
    "We've used the pre trained neural network to extract features from our training images. Now we're ready to train a new neural network that uses those extracted features.\n",
    "\n",
    "### Differences\n",
    "The code is exactly like training any other neural network but with two small differences. \n",
    "1. The first difference is how we load our training data Instead of loading raw images to train with, we're gonna load the features that we extracted with the pre trained VGG 16 neural network. If you look at the file list on the left, you can see that we already have our extracted features stored in a file called x train.dat and our labels stored in a file called y train.dat.\n",
    "\n",
    "2. The second difference is in how we define our layers. Since we use VGG 16 to extract features from our image, this neural network has no convolutional layers. Instead it only has the final dense layers of the neural network. These are the only layers that we'll be retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set\n",
    "x_train = joblib.load('x_train.dat')\n",
    "y_train = joblb.load('y_train.dat')\n",
    "\n",
    "### Create a model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Save neural network structure\n",
    "transfer_model_structure = model.to_json()\n",
    "f = Path('transfer_model_structure.json')\n",
    "f.write_text(transfer_model_structure)\n",
    "\n",
    "# Save neural network's trained weights\n",
    "model.save_weights('transfer_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions with Transfer Learning\n",
    "\n",
    "We have used the pre-trained models, extracted features, created a new model that will train the dense layers, extracted the structure and trained weights using the combination of the two. Now we will make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the json file that contains the transfer model structure\n",
    "f = Path('transfer_model_structure.json')\n",
    "model_structure = f.read_text()\n",
    "\n",
    "# Recreate the Keras model object from the json daa\n",
    "model = model_from_json(model_structure)\n",
    "\n",
    "# Re-load the transfer model's trained weights\n",
    "model.load_weights('transfer_model_weights.h5')\n",
    "\n",
    "# Load an image file to test and resize it to 64x64\n",
    "img = image.load_img('Images/23-potato.png', target_size=(64, 64))\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "image_array = image.img_to_array(img)\n",
    "\n",
    "# Add a forth dimension to the image\n",
    "images = np.expand_dims(image_array, axis=0)\n",
    "\n",
    "# Normalize the data\n",
    "images = vgg16.preprocess_input(images)\n",
    "\n",
    "# Use the pre-trained neural network to extract features from the test image\n",
    "feature_extraction_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "features = feature_extraction_model.predict(images)\n",
    "\n",
    "# Given the extracted features, make a final prediction using the model\n",
    "results = model.predict(features)\n",
    "\n",
    "# Check first result since we only have one image\n",
    "single_result = results[0][0]\n",
    "\n",
    "# Print the result\n",
    "print(\"Likelihood that this image contains a dog: {}%\".format(int(single_result * 100)))\n",
    "\n",
    "Image.open('Images/23-potato.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (TensorFlow)",
   "language": "python",
   "name": "tf-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
