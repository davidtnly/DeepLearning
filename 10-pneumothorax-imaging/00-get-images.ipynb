{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/97203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob2\n",
    "import pydicom\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure\n",
    "import sys\n",
    "# sys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation/')\n",
    "from mask_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 256\n",
    "sz0 = 1024\n",
    "PATH_TRAIN = 'input/dicom-images-train/'\n",
    "PATH_TEST = 'input/dicom-images-test/'\n",
    "train_out = 'train.zip'\n",
    "test_out = 'test.zip'\n",
    "mask_out = 'masks.zip'\n",
    "train = glob2.glob(os.path.join(PATH_TRAIN, '**/*.dcm'))\n",
    "test = glob2.glob(os.path.join(PATH_TEST, '**/*.dcm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train-rle.csv').set_index('ImageId')\n",
    "idxs = set(df.index)\n",
    "train_names = []\n",
    "for f in train: #remove images without labels\n",
    "    name = f.split('/')[-1][:-4]\n",
    "    if name in idxs: train_names.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_images(filename, arch_out, sz=sz):\n",
    "    ds = pydicom.read_file(str(filename))\n",
    "    img = ds.pixel_array\n",
    "    img = cv2.resize(img, (sz, sz))\n",
    "    img = exposure.equalize_adapthist(img) # contrast correction\n",
    "    x_tot = img.mean() #image statistics\n",
    "    x2_tot = (img**2).mean()\n",
    "    img = ((img*255)).clip(0,255).astype(np.uint8)\n",
    "    output = cv2.imencode('.png',img)[1]\n",
    "    name = filename.split('/')[-1][:-4] + '.png'\n",
    "    arch_out.writestr(name, output)\n",
    "    return x_tot, x2_tot\n",
    "\n",
    "def get_stats(stats): # get dataset statistics \n",
    "    x_tot, x2_tot = 0.0, 0.0\n",
    "    for x, x2 in stats:\n",
    "        x_tot += x\n",
    "        x2_tot += x2\n",
    "    \n",
    "    img_avr =  x_tot/len(stats)\n",
    "    img_std =  np.sqrt(x2_tot/len(stats) - img_avr**2)\n",
    "    print('mean:',img_avr, ', std:', img_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_stats = []\n",
    "with zipfile.ZipFile(train_out, 'w') as arch:\n",
    "    for fname in tqdm(train_names, total=len(train_names)):\n",
    "        trn_stats.append(convert_images(fname,arch))\n",
    "\n",
    "test_stats = []        \n",
    "with zipfile.ZipFile(test_out, 'w') as arch:\n",
    "    for fname in tqdm(test, total=len(test)):\n",
    "        test_stats.append(convert_images(fname,arch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats(trn_stats)\n",
    "get_stats(test_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_coverage = []\n",
    "mask_count = 0\n",
    "with zipfile.ZipFile(mask_out, 'w') as arch:\n",
    "    for idx in tqdm(idxs):\n",
    "        masks = df.loc[idx,' EncodedPixels']\n",
    "        img = np.zeros((sz0,sz0))\n",
    "        #do conversion if mask is not \" -1\"\n",
    "        if(type(masks) != str or (type(masks) == str and masks != ' -1')):\n",
    "            if(type(masks) == str): masks = [masks]\n",
    "            else: masks = masks.tolist()\n",
    "            mask_count +=1\n",
    "            for mask in masks:\n",
    "                img += rle2mask(mask, sz0, sz0).T\n",
    "        mask_coverage.append(img.mean())\n",
    "        img = cv2.resize(img, (sz, sz))\n",
    "        output = cv2.imencode('.png',img)[1]\n",
    "        name = idx + '.png'\n",
    "        arch.writestr(name, output)\n",
    "\n",
    "print('mask coverage:', np.mean(mask_coverage)/255, ', mask count:', mask_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 736\n",
    "with zipfile.ZipFile(train_out, 'r') as arch:\n",
    "    fname = sorted(arch.namelist())[idx]\n",
    "    flags = cv2.IMREAD_GRAYSCALE\n",
    "    img = cv2.imdecode(np.frombuffer(arch.read(fname), np.uint8), flags)\n",
    "    \n",
    "with zipfile.ZipFile(mask_out, 'r') as arch:\n",
    "    fname = sorted(arch.namelist())[idx]\n",
    "    flags = cv2.IMREAD_GRAYSCALE\n",
    "    mask = cv2.imdecode(np.frombuffer(arch.read(fname), np.uint8), flags)\n",
    "    \n",
    "plt.figure()\n",
    "plt.imshow(Image.fromarray(img))\n",
    "plt.imshow(Image.fromarray(mask), alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (TensorFlow)",
   "language": "python",
   "name": "tf-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
