{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindBatchSize(model):\n",
    "    \"\"\"#model: model architecture, that is yet to be trained\"\"\"\n",
    "    import os, sys, psutil, gc, tensorflow, keras\n",
    "    import numpy as np\n",
    "    from keras import backend as K\n",
    "    BatchFound= 16\n",
    "\n",
    "    try:\n",
    "        total_params= int(model.count_params());    GCPU= \"CPU\"\n",
    "        #find whether gpu is available\n",
    "        try:\n",
    "            if K.tensorflow_backend._get_available_gpus()== []:\n",
    "                GCPU= \"CPU\";    #CPU and Cuda9GPU\n",
    "            else:\n",
    "                GCPU= \"GPU\"\n",
    "        except:\n",
    "            from tensorflow.python.client import device_lib;    #Cuda8GPU\n",
    "            def get_available_gpus():\n",
    "                local_device_protos= device_lib.list_local_devices()\n",
    "                return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "            if \"gpu\" not in str(get_available_gpus()).lower():\n",
    "                GCPU= \"CPU\"\n",
    "            else:\n",
    "                GCPU= \"GPU\"\n",
    "\n",
    "        #decide batch size on the basis of GPU availability and model complexity\n",
    "        if (GCPU== \"GPU\") and (os.cpu_count() >15) and (total_params <1000000):\n",
    "            BatchFound= 64    \n",
    "        if (os.cpu_count() <16) and (total_params <500000):\n",
    "            BatchFound= 64  \n",
    "        if (GCPU== \"GPU\") and (os.cpu_count() >15) and (total_params <2000000) and (total_params >=1000000):\n",
    "            BatchFound= 32      \n",
    "        if (GCPU== \"GPU\") and (os.cpu_count() >15) and (total_params >=2000000) and (total_params <10000000):\n",
    "            BatchFound= 16  \n",
    "        if (GCPU== \"GPU\") and (os.cpu_count() >15) and (total_params >=10000000):\n",
    "            BatchFound= 8       \n",
    "        if (os.cpu_count() <16) and (total_params >5000000):\n",
    "            BatchFound= 8    \n",
    "        if total_params >100000000:\n",
    "            BatchFound= 1\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "\n",
    "        #find percentage of memory used\n",
    "        memoryused= psutil.virtual_memory()\n",
    "        memoryused= float(str(memoryused).replace(\" \", \"\").split(\"percent=\")[1].split(\",\")[0])\n",
    "        if memoryused >75.0:\n",
    "            BatchFound= 8\n",
    "        if memoryused >85.0:\n",
    "            BatchFound= 4\n",
    "        if memoryused >90.0:\n",
    "            BatchFound= 2\n",
    "        if total_params >100000000:\n",
    "            BatchFound= 1\n",
    "        print(\"Batch Size:  \"+ str(BatchFound));    gc.collect()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    memoryused= [];    total_params= [];    GCPU= \"\";\n",
    "    del memoryused, total_params, GCPU;    gc.collect()\n",
    "    return BatchFound"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (TensorFlow)",
   "language": "python",
   "name": "tf-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
