{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "The first model here is a multi-layer architecture consisting of alternating separable and normal convolutions and nonlinearities. These layers are followed by fully connected layers leading into a sigmoid. The model follows the architecture similar to VGG16 by K. Simonyan and A. Zisserman.\n",
    "\n",
    "This model achieves a peak performance of about 94% accuracy within 11 minutes of training time on a GPU. It consists of 2,313,441 learnable parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABECAYAAAAiJuZQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAABr0lEQVR4nO3YvUkEURiF4VkRNhJx1cREEGTRRLABKzAx08AmLMEeBCuwAquwgsFANl4RDAQR5NrA7kTec/15nvRLzsDwBndUSukAyFhpPQDgPxFdgCDRBQgSXYAg0QUIWh06Hh0el/XxJLUlbr42bj2hqq2Vt9YTqtl4mbeeUNVj97f/zbIzmJ5frzy9Pvd9v73oNvjl6+NJd3lwVWfVD3B7st96QlXnaw+tJ1RzdnfTekJVp597rSdU9XG92XpCVe8X97NlN88LAEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaNSytLjdDqdd103y80B+BN2+77fXnQYjC4A38vzAkCQ6AIEiS5AkOgCBIkuQNAXNFUnREA1iFAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Images\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import imgaug as aug\n",
    "import imgaug.augmenters as imaug\n",
    "\n",
    "# Toolbox\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import random\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Deep learning libraries\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, ReLU, Activation\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Evaluation libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "# Misc\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# Preset data display\n",
    "pd.options.display.max_seq_items = 1000\n",
    "pd.options.display.max_rows =1000\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "# Set notebook colors and palette\n",
    "flatui = ['#9b59b6', '#3498db', '#95a5a6', '#e74c3c', '#34495e', '#2ecc71']\n",
    "sns.set_palette(flatui)\n",
    "sns.palplot(sns.color_palette(flatui))\n",
    "sns.set_style('white')\n",
    "sns.set_color_codes(palette='deep')\n",
    "# Favorite code to use: #34995e\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "seed = 100\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gen_first_model', 'test', 'test_gen', 'train', 'train_gen', 'val', 'val_gen']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set directory\n",
    "PATH = 'C:\\\\Users\\\\' + os.getlogin() + '\\\\Documents\\\\Programming\\\\DeepLearning\\\\07-pneunomia-radiograph-imaging\\\\images'\n",
    "os.chdir(PATH)\n",
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Path\n",
    "MAIN_PATH = Path(PATH)\n",
    "\n",
    "# Path to train directory (Fancy pathlib...no more os.path!!)\n",
    "train_dir = MAIN_PATH / 'train'\n",
    "\n",
    "# Path to validation directory\n",
    "val_dir = MAIN_PATH / 'val'\n",
    "\n",
    "# Path to test directory\n",
    "test_dir = MAIN_PATH / 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to training images\n",
    "normal_cases_dir = train_dir / 'NORMAL'\n",
    "pneunomia_cases_dir = train_dir / 'PNEUMONIA'\n",
    "\n",
    "# List of all images for training\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneunomia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# Create empty list to store the training data\n",
    "train_data = []\n",
    "\n",
    "# Loop through normal images and label = 0\n",
    "for img in normal_cases:\n",
    "    train_data.append((img, 0))\n",
    "    \n",
    "# Loop through pneunomia images and label = 1\n",
    "for img in pneumonia_cases:\n",
    "    train_data.append((img, 1))\n",
    "    \n",
    "# Create a dataframe\n",
    "train_data = pd.DataFrame(train_data, columns=['image', 'label'], index=None)\n",
    "\n",
    "# Shuffle\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to testing images\n",
    "normal_cases_dir = test_dir / 'NORMAL'\n",
    "pneunomia_cases_dir = test_dir / 'PNEUMONIA'\n",
    "\n",
    "# List of all images for training\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneunomia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# Create empty list to store the training data\n",
    "test_data = []\n",
    "\n",
    "# Loop through normal images and label = 0\n",
    "for img in normal_cases:\n",
    "    test_data.append((img, 0))\n",
    "    \n",
    "# Loop through pneunomia images and label = 1\n",
    "for img in pneumonia_cases:\n",
    "    test_data.append((img, 1))\n",
    "    \n",
    "# Create a dataframe\n",
    "test_data = pd.DataFrame(test_data, columns=['image', 'label'], index=None)\n",
    "\n",
    "# # Shuffle\n",
    "# test_data = test_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out different ways from other kernels on pulling images to test speed/readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "TARGET_SIZE = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating images\n",
    "\n",
    "Keras allows for image augmentation. This is where we generate batches of image data with real time data augmentation. The data will be looped over in batches indefinitely. I also tested it out in one of my development notebooks [here](https://github.com/davidtnly/DeepLearning/blob/master/00-development/12-image-augment.ipynb).\n",
    "\n",
    "[TensorFlow Keras ImageDataGenerator Doc](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Use ImageDataGenerator to feed into the network in batch sizes\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Set paths and parameters\n",
    "train_gen_path = MAIN_PATH / 'train_gen'\n",
    "test_gen_path = MAIN_PATH / 'test_gen'\n",
    "\n",
    "# Set generation object path\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(TARGET_SIZE, TARGET_SIZE),\n",
    "    class_mode='binary',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    "    save_to_dir=train_gen_path\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(TARGET_SIZE, TARGET_SIZE),\n",
    "    class_mode='binary',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    "    save_to_dir=test_gen_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get test data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_arrays = []\n",
    "test_labels = []\n",
    "\n",
    "# Loop through the test data\n",
    "for num in range(test_data.image.count()):\n",
    "    for img in test_data:\n",
    "        # Read the image path and resize to (150, 150)\n",
    "        img = plt.imread(test_data.iloc[num].image)\n",
    "        img = cv2.resize(img, (TARGET_SIZE, TARGET_SIZE))\n",
    "        # Convert to 3D and scale\n",
    "        img = np.dstack([img, img, img])\n",
    "        img = img.astype('float32') / 255\n",
    "        label = test_data.iloc[num].label\n",
    "        \n",
    "        # Append to list\n",
    "        test_data_arrays.append(img)\n",
    "        test_labels.append(label)\n",
    "\n",
    "# Convert to arrays\n",
    "test_data_arrays = np.array(test_data_arrays)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "780"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network\n",
    "def build_model():\n",
    "    \n",
    "    # Input layer\n",
    "    inputs = Input(shape=(TARGET_SIZE, TARGET_SIZE, 3), name='input_layer')\n",
    "    \n",
    "    # First convolutional block\n",
    "    x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same', name='conv1_1')(inputs)\n",
    "    x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same', name='conv1_2')(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), name='pool1_1')(x) # max pooling operation for spatial data\n",
    "    \n",
    "    # Second convolutional block\n",
    "    x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', name='conv2_1')(x)\n",
    "    x = BatchNormalization(name='bn2_1')(x) # stabilizing the learning process; reduce internal covariate shifting\n",
    "    x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', name='conv2_2')(x)\n",
    "    x = BatchNormalization(name='bn2_2')(x) \n",
    "    x = MaxPool2D(pool_size=(2, 2), name='pool2_1')(x)\n",
    "    \n",
    "    # Third convolutional block\n",
    "    x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same', name='conv3_1')(x)\n",
    "    x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same', name='conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn3_1')(x) \n",
    "    x = MaxPool2D(pool_size=(2, 2), name='pool3_1')(x)   \n",
    "    \n",
    "    # Fourth convolutional block\n",
    "    x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same', name='conv4_1')(x)\n",
    "    x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same', name='conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4_1')(x) \n",
    "    x = MaxPool2D(pool_size=(2, 2), name='pool4_1')(x)\n",
    "#     x = Dropout(rate=0.20, name='dropout4_1')(x) # prevent network from overfitting; probabilistically reduce the network capacity\n",
    "    \n",
    "    # Fifth convolutional block\n",
    "    x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same', name='conv5_1')(x)\n",
    "    x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same', name='conv5_2')(x)\n",
    "    x = BatchNormalization(name='bn5_1')(x) \n",
    "    x = MaxPool2D(pool_size=(2, 2), name='pool5_1')(x)\n",
    "#     x = Dropout(rate=0.20, name='dropout5_1')(x) \n",
    "    \n",
    "    # Fully connected block\n",
    "    x = Flatten(name='flatten6_1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc6_1')(x)\n",
    "    x = Dropout(rate=0.7, name='dropout6_1')(x)\n",
    "    x = Dense(128, activation='relu', name='fc6_2')(x)\n",
    "    x = Dropout(rate=0.5, name='dropout6_2')(x)\n",
    "    x = Dense(64, activation='relu', name='fc6_3')(x)\n",
    "    x = Dropout(rate=0.3, name='dropout6_3')(x)\n",
    "    \n",
    "    # Output\n",
    "    output = Dense(units=1, activation='sigmoid', name='output')(x) # 1 so fewer parameters and computation are needed\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model\n",
    "\n",
    "The primary use case is to automatically save checkpoints during and at the end of training. This way you can use a trained model without having to retrain it, or pick-up training where you left of—in case the training process was interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model and compiling\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Save weights\n",
    "# checkpoint_path = '../model_2/best_weights-cp-{epoch:04d}.ckpt'\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "                             #filepath=checkpoint_path,\n",
    "                             #period=5, # save every 5 epochs\n",
    "                             filepath='best_weights_model_16.hdf5',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True)\n",
    "\n",
    "# Callbacks - view internal states and statistics of the model during training\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.3,\n",
    "                              patience=2,\n",
    "                              verbose=2,\n",
    "                              mode='max')\n",
    "\n",
    "# Stop if model is not improving\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           min_delta=0.1,\n",
    "                           patience=1,\n",
    "                           mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "81/81 [==============================] - 77s 945ms/step - loss: 0.3417 - acc: 0.8324 - val_loss: 0.6822 - val_acc: 0.7344\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_gen, \n",
    "    steps_per_epoch=train_gen.samples // BATCH_SIZE,\n",
    "    epochs=1,\n",
    "    validation_data=test_gen,\n",
    "    validation_steps=test_gen.samples // BATCH_SIZE,\n",
    "    callbacks=[checkpoint, lr_reduce] # early_stop\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (TensorFlow)",
   "language": "python",
   "name": "tf-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
