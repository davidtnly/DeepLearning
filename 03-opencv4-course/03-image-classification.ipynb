{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV's DNN module as an inference engine\n",
    "\n",
    "The imagenet image database is organized according to the wordnet hierarchy. Each meaningful concept in wordnet, which could be multiple words is called a synonym set or a synset. This 1000 classes are stored in this synset file. So if we open this synset file, we can see the 1000 different categories, and here, each row corresponds to a category and this starts with an id, and then one or more words describing the category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Load img\n",
    "img = cv2.imread('Images/typewriter.jpg')\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n01443537 goldfish, Carassius auratus',\n",
       " 'n01484850 great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias',\n",
       " 'n01491361 tiger shark, Galeocerdo cuvieri',\n",
       " 'n01494475 hammerhead, hammerhead shark',\n",
       " 'n01496331 electric ray, crampfish, numbfish, torpedo',\n",
       " 'n01498041 stingray',\n",
       " 'n01514668 cock',\n",
       " 'n01514859 hen',\n",
       " 'n01518878 ostrich, Struthio camelus']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the synset classes file and strip off any characters\n",
    "all_rows = open('synset_words.txt').read().strip().split('\\n')\n",
    "\n",
    "all_rows[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['goldfish, Carassius auratus',\n",
       " 'great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias',\n",
       " 'tiger shark, Galeocerdo cuvieri',\n",
       " 'hammerhead, hammerhead shark',\n",
       " 'electric ray, crampfish, numbfish, torpedo',\n",
       " 'stingray',\n",
       " 'cock',\n",
       " 'hen',\n",
       " 'ostrich, Struthio camelus']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the different descriptions and not the id; we can use a list comprehension. \n",
    "# Find classes; looking for a space, and we don't want to include the id for r in all_rows; +1 for text after space\n",
    "classes = [r[r.find(' ') + 1:] for r in all_rows]\n",
    "\n",
    "classes[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tench, Tinca tinca\n",
      "1 goldfish, Carassius auratus\n",
      "2 great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias\n",
      "3 tiger shark, Galeocerdo cuvieri\n"
     ]
    }
   ],
   "source": [
    "# Loop through a few classes with enumerate\n",
    "for i, c in enumerate(classes):\n",
    "    if i==4:\n",
    "        break\n",
    "    else:\n",
    "        print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ready to pass the image through a pre-trained model\n",
    "We're now in a position to actually pass this image through a pre-trained model. So I'm going to just press any key to close this image and next we look at passing the image through a pre-trained model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output of Image Classification Using Caffe Model\n",
    "\n",
    "So we've loaded the different classes of ImageNet and we're going to use the OpenCV DNN module as an inference engine. What we're going to do here is pass an image through a pre-trained model that has been trained on the 1,000 classes of ImageNet. The model will then output the probability the image contains each of the 1,000 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### readNetFromCaffe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Open CV supports models from Caffee, TenserFlow, Torch, DarkNet and models from the omnx format all you need to do is load the models in wait and any configuration files for your use case.\n",
    "\n",
    "So readNetFromCaffe takes in as arguments the path to the prottotxt file with text descriptions of the network architecture and the path to the caffeModel file with the train model.\n",
    "\n",
    "    cv2.dnn(readNetFromCaffe(prototxt, caffeModel)\n",
    "            \n",
    "So readNetFromCaffe takes in as arguments the path to the prottotxt file with text descriptions of the network architecture and the path to the caffeModel file with the train model.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the caffe file\n",
    "net = cv2.dnn.readNetFromCaffe('CaffeModel/bvlc_googlenet.prototxt', 'CaffeModel/bvlc_googlenet.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dnn_Net 000001DB38FEAE30>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Know the model definition and check what size the image needs to be. Now the model definition from the prototxt file, tells us that the model expects images of size 224 by 224. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the blob after getting net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create blob\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set forward pass to get the predictions for each of the 1,000 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set forward pass to get the predictions for each of the 1,000 classes\n",
    "output = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All of classes and probability; Get top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 probabilities\n",
    "idx = np.argsort(output[0])[::-1][:5] # first element, sort backwards, get first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([878, 810, 753, 844, 827], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. typewriter keyboard (878): Probability 0.854%\n",
      "2. space bar (810): Probability 0.0545%\n",
      "3. radiator (753): Probability 0.0201%\n",
      "4. switch, electric switch, electrical switch (844): Probability 0.00888%\n",
      "5. stove (827): Probability 0.00873%\n"
     ]
    }
   ],
   "source": [
    "# Loop through each row\n",
    "for i, ids in enumerate(idx):\n",
    "    print('{}. {} ({}): Probability {:.3}%'.format(i+1, classes[ids], ids, output[0][ids]))\n",
    "#     print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. typewriter keyboard (878): Probability 0.854%\n",
      "2. space bar (810): Probability 0.0545%\n",
      "3. radiator (753): Probability 0.0201%\n",
      "4. switch, electric switch, electrical switch (844): Probability 0.00888%\n",
      "5. stove (827): Probability 0.00873%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load img\n",
    "img = cv2.imread('Images/typewriter.jpg')\n",
    "\n",
    "# Read the synset classes file and strip off any characters\n",
    "all_rows = open('synset_words.txt').read().strip().split('\\n')\n",
    "\n",
    "# Grab the different descriptions and not the id; we can use a list comprehension. \n",
    "# Find classes; looking for a space, and we don't want to include the id for r in all_rows; +1 for text after space\n",
    "classes = [r[r.find(' ') + 1:] for r in all_rows]\n",
    "\n",
    "# Read the caffe file\n",
    "net = cv2.dnn.readNetFromCaffe('CaffeModel/bvlc_googlenet.prototxt', 'CaffeModel/bvlc_googlenet.caffemodel')\n",
    "\n",
    "# Create blob\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (224, 224))\n",
    "\n",
    "# Set Input\n",
    "net.setInput(blob)\n",
    "\n",
    "# Set forward pass to get the predictions for each of the 1,000 classes\n",
    "output = net.forward()\n",
    "\n",
    "# Top 5 probabilities\n",
    "idx = np.argsort(output[0])[::-1][:5] # first element, sort backwards, get first 5\n",
    "\n",
    "# Loop through each row\n",
    "for i, ids in enumerate(idx):\n",
    "    print('{}. {} ({}): Probability {:.3}%'.format(i+1, classes[ids], ids, output[0][ids]))\n",
    "\n",
    "# Show image\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (OpenCV)",
   "language": "python",
   "name": "ocv4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
