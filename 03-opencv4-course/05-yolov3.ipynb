{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv3 is a popular object detection algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The network only needs to view the image one time, and then the bounding boxes are weighted by the predictive probabilities. We can set thresholds. So let's say we set it at 80%. Then, only if the YOLO algorithm is more than 80% sure that it has detected a dog, for example, will it draw a bounding box around it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use OpenCV for YOLO ?\n",
    "\n",
    "Here are a few reasons you may want to use OpenCV for YOLO\n",
    "\n",
    "1. Easy integration with an OpenCV application: If your application already uses OpenCV and you simply want to use YOLOv3, you don’t have to worry about compiling and building the extra Darknet code.\n",
    "\n",
    "\n",
    "2. OpenCV CPU version is 9x faster: OpenCV’s CPU implementation of the DNN module is astonishingly fast. For example, Darknet when used with OpenMP takes about 2 seconds on a CPU for inference on a single image. In contrast, OpenCV’s implementation runs in a mere 0.22 seconds! Check out table below.\n",
    "\n",
    "\n",
    "3. Python support: Darknet is written in C, and it does not officially support Python. In contrast, OpenCV does. There are python ports available for Darknet though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So YOLOv3 has been trained on the COCO dataset, which has 80 different classes of objects. We'll use a pretrained model from Darknet, and I've just downloaded the config and weight files from here. So let's have a quick walkthrough of the code. And you should see a couple of things you recognize. In line 25, we load the config and weight files into the Darknet architecture. Scrolling further down, in line 125, we create our 4D blob. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage:\n",
    "# python yolo.py --video=<path to video file>\n",
    "# python yolo.py --image=<path to image file>\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "# Initialize the parameters\n",
    "confThreshold = 0.5  #Confidence threshold\n",
    "nmsThreshold = 0.4   #Non-maximum suppression threshold\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Object Detection using YOLO in OPENCV')\n",
    "parser.add_argument('--image', help='Path to image file.')\n",
    "parser.add_argument('--video', help='Path to video file.')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Load names of classes from coco\n",
    "\n",
    "classes = open('YOLOv3/coco.names').read().strip().split('\\n')\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(\"YOLOv3/yolov3.cfg\", \"YOLOv3/yolov3.weights\")\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "\n",
    "# Get the names of the output layers\n",
    "def getOutputsNames(net):\n",
    "    # Get the names of all the layers in the network\n",
    "    layersNames = net.getLayerNames()\n",
    "    # Get the names of the output layers, i.e. the layers with unconnected outputs\n",
    "    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Draw the predicted bounding box\n",
    "def drawPred(classId, conf, left, top, right, bottom):\n",
    "    # Draw a bounding box.\n",
    "    cv2.rectangle(frame, (left, top), (right, bottom), (255, 178, 50), 3)\n",
    "\n",
    "    label = '%.2f' % conf\n",
    "\n",
    "    # Get the label for the class name and its confidence\n",
    "    if classes:\n",
    "        assert(classId < len(classes))\n",
    "        label = '%s:%s' % (classes[classId], label)\n",
    "\n",
    "    #Display the label at the top of the bounding box\n",
    "    labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    top = max(top, labelSize[1])\n",
    "    cv2.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (255, 255, 255), cv2.FILLED)\n",
    "    cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 1)\n",
    "\n",
    "# Remove the bounding boxes with low confidence using non-maxima suppression\n",
    "def postprocess(frame, outp):\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth = frame.shape[1]\n",
    "\n",
    "    # Scan through all the bounding boxes output from the network and keep only the\n",
    "    # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outp:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            confidence = scores[classId]\n",
    "            if confidence > confThreshold:\n",
    "                center_x = int(detection[0] * frameWidth)\n",
    "                center_y = int(detection[1] * frameHeight)\n",
    "                width = int(detection[2] * frameWidth)\n",
    "                height = int(detection[3] * frameHeight)\n",
    "                left = int(center_x - width / 2)\n",
    "                top = int(center_y - height / 2)\n",
    "                classIds.append(classId)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([left, top, width, height])\n",
    "\n",
    "    # Perform non maximum suppression to eliminate redundant overlapping boxes with\n",
    "    # lower confidences.\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        left = box[0]\n",
    "        top = box[1]\n",
    "        width = box[2]\n",
    "        height = box[3]\n",
    "        drawPred(classIds[i], confidences[i], left, top, left + width, top + height)\n",
    "\n",
    "outputFile = \"YOLOv3_output.avi\"\n",
    "if (args.image):\n",
    "    # Open the image file\n",
    "    if not os.path.isfile(args.image):\n",
    "        print(\"Input image file \", args.image, \" doesn't exist\")\n",
    "        sys.exit(1)\n",
    "    cap = cv2.VideoCapture(args.image)\n",
    "    outputFile = args.image[:-4]+'_YOLOv3_output.jpg'\n",
    "else:\n",
    "    # Open the video file\n",
    "    if not os.path.isfile(args.video):\n",
    "        print(\"Input video file \", args.video, \" doesn't exist\")\n",
    "        sys.exit(1)\n",
    "    cap = cv2.VideoCapture(args.video)\n",
    "    outputFile = args.video[:-4]+'_YOLOv3_output.avi'\n",
    "\n",
    "# Get the video writer initialized to save the output video\n",
    "if (not args.image):\n",
    "    vid_writer = cv2.VideoWriter(outputFile, cv2.VideoWriter_fourcc('M','J','P','G'), 30, (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "\n",
    "    hasFrame, frame = cap.read()\n",
    "\n",
    "    # Stop if end of video\n",
    "    if not hasFrame:\n",
    "        print(\"File with YOLOv3 output is here :  \", outputFile)\n",
    "        cv2.waitKey(5000)\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "    # Create a 4D blob from a frame.\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255, (416,416), [0,0,0], 1, crop=False)\n",
    "\n",
    "    # Sets the input to the network\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Runs the forward pass to get output of the output layers\n",
    "    outp = net.forward(getOutputsNames(net))\n",
    "\n",
    "    # Remove the bounding boxes with low confidence\n",
    "    postprocess(frame, outp)\n",
    "\n",
    "    # Write the frame with the detection boxes\n",
    "    if (args.image):\n",
    "        cv2.imwrite(outputFile, frame.astype(np.uint8))\n",
    "    else:\n",
    "        vid_writer.write(frame.astype(np.uint8))\n",
    "\n",
    "    cv2.imshow('Image', frame)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (OpenCV)",
   "language": "python",
   "name": "ocv4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
